# 搜索引擎 设计

## 一、需求背景

* 引擎分信息引擎与资源引擎，信息引擎是获取作品信息的引擎，资源引擎即获取作品下载链接的引擎。
* 无论是信息引擎，还是资源引擎，一次只能搜索一个作品信息，搜索的字段是作品番号（作品番号可能有两种或以上格式，其中一种是标准格式）。
* 搜索引擎是可配置化的，通过编写配置，用户可自己创建引擎（同时，用户也可以管理资源引擎，设置调用的优先顺序、关闭或开启）。
* 进行信息或资源搜索时，程序会访问引擎列表，依序逐一调用已开启的引擎，任一引擎获取到数据即中止调用。
* 列表与筛选：一个作品的有效下载链接可能不止一个，为了尽可能收集这些下载链接，通常需要先访问一个包含多条目标的列表页面，并根据 title、size 等信息筛选正确的目标；另外，到达具体的作品信息前，也通常需要通过列表页获取具体信息的页面链接。
* 二级页面：有时，通过列表页还不能获取真正的链接或全部作品信息，其藏在下一级页面，列表页只是提供了访问下级页面的 url，需要获取这些 url，经过筛选后逐一访问这些二级页面，获取真正的下载链接，最后组合成一个链接数组返回。
* 绕过机器人验证：有相当多的站点会设置机器人访问限制，需要想办法绕过。



## 二、配置设计

| 配置项   | 意义                     | 值类型 | 说明                                                         |
| -------- | ------------------------ | ------ | ------------------------------------------------------------ |
| name     | 引擎名称                 | string | 代码调用引擎时的查询名称                                     |
| root     | 主页根地址               | string | 值为 protocol://host。主页可能随时会失效，需要用户持续维护。 |
| delay?   | DOM 获取延迟（可选）     | number | 设置在每次请求远程 url 前，要延迟多少毫秒。如果需要避免被远程站点判断为机器人而Block，可以尝试设置该选项。默认 300~2000 |
| timeout? | 单次任务超时设置（可选） | number | 超时设置，单位毫秒，默认 20000 毫秒                          |
| steps    | 流程步骤                 | step[] | steps 是一个数组，规定了资源获取的流程，用来处理多层子级页的访问。<br />数组的每一个子项都是一个 step，一个 step 对应一级页面访问。<br />step 链式执行，一个 step 的输出是下一个 step 的输入，<br />第一个 step 的输入参数由 input 配置指明。<br />**step 的配置是一个对象，见下方 “ step 的配置子项 ”* |
| input    | 启动参数                 | string | 第一个 step 的输入参数配置，是一个支持查询参数的 url 字符串。 |
| referer  | 请求头 referer           | string | 用于破解目标网站对 referer 的限制，支持查询参数<br />**Tips: 成功破解一般需要 `origin+pathname` ，例如配置为："${root}/search"* |

step 的配置子项：

| 配置项  | 意义             | 值类型                                                      | 说明                                                         |
| ------- | ---------------- | ----------------------------------------------------------- | ------------------------------------------------------------ |
| list?   | 列表搜索（可选） | {<br />    selector: string, <br />    filter:string<br />} | 配置了 list，说明需要在 step 中执行列表搜索，并筛选数据<br />list 有两项子配置：<br />* selector：list 的 CSS 查询器<br />* filter：要应用的筛选器名称，筛选器不是数组，一次只能配置一个 |
| dataMap | 数据地图         | object                                                      | 提供给 Spider 的，用于搜索数据的地图<br />如果不是最后一个 step，则 url 也是一个地图要素，应该配置到 dataMap 中 <br />url 有专属的 action，可以配置进来 |



## 三、流程设计

资源搜索启动后，先读取引擎的配置，根据 step 配置逐一访问页面并获取需要的数据，将每一步的获取到的数据组合到一起，就是最终的数据输出。 

资源的获取流程由多个 step 组成，因此流程的设计主要是 step 的设计。

### Steps 的设计概要

* steps 是一个数组，规定资源获取的流程。往往资源的获取不是一步到位的，有二级页面，steps 就是用来应对这种情况的。
* 一个 step 是一个独立的处理过程，代表一级页面访问（对一组同类页面的访问）。有输入参数，也有输出参数。
* step 按 steps 数组的元素顺序链式执行，上一个 step 的输出，是下一个 step 的输入。
* step 的执行，直到最后一个 step 返回为止，最后一个 step 的输出就是整个过程的最后输出。

### Step 的输入、输出

* 为了能够链式执行，step 输入与输出的数据类型相同。

* Step 的输入或输出参数是一个对象，格式是：```{ urls?:string[], data:object }```。

* `urls` 是下一个 step 要访问的目标网址清单，最后一个 step 则不需要返回 `urls`。

  有些 step 存在 list 搜索，有些则没有。为了统一返回类型，在一个 step 中获取到的多个或单个 url，都拼成数组返回，即单个 url 也要拼成一个单元素数组。

* `data` 是上一个 step 返回的数据(作为输入参数时)，或是当前 step 返回的数据(作为输出参数时)。

  - 虽然一个 step 中可能存在列表搜索，也可能因为访问多个页面而产生多条数据，但引擎运行的最终返回结果还是单一的作品数据对象。换句话说，每个 step 的输出也都应该是一个单一对象，在返回前，应该把多条数据合并为一个单一数据对象输出。
  - 每个合并后的 data 对象，在返回前，还需要与输入的 data 合并。这样，data 借助 step 链层层传递与合并，最后一个 step 返回的 data 对象就是整个引擎的运行结果。
  
* 第一个 step 的输入参数由 `input` 配置指明，但 `input` 配置的字符串并不是引擎运行过程中真正传递给第一个 step 的输入参数。

  input 配置中允许添加查询参数（形如 `input: "${root}/cn/search/${search}"`），查询参数指向的是引擎运行时的上下文变量，需要将 input 配置字符串的查询参数替换成其指向的上下文变量值，才能传递给第一个 step，开启整个引擎的运行。

### Step 的内部行为

* 首先，遍历输入参数中的 urls 数组，获取每个 url 对应的 DOM。
* 对于获取到的 DOM，如果不为空，则依据是否配置 `list`，决定执行列表搜索，还是直接搜索。
* 列表搜索交付给 `ListSpider` 执行，依据 DOM 及 `list` 配置初始化一个 `ListSpider`，调用其 `search(dataMap)` 方法执行，返回一个包含了多个搜索结果的对象数组。
* 直接搜索就是用 DOM 初始化一个 Spider，调用其 `search(dataMap)` 方法， 返回一个搜索结果对象。
* 每一次遍历所获取的结果对象数组，或结果对象，遍历完后全都拼到一个大数组中，分别提取其中的 url 及 data 进行数据的去重合并。
* 对于 url，从大数组提取出来后，直接拼接为一个 urls 数组。
* 对于 data，则要根据“组合规则”，进行多合一，合并为一个 data 对象。
* 合并后的 data 要继续与输入的 data 合并。
* 组合 ulrs 和 data，完成 step 结果返回。

### Step 输出数据的组合规则

* 输出数据的多合一合并依据 dataMap 中的地图要素的结果类型区别处理：
  - 当地图要素是文本结果类型时，采用 “归一” 操作：只采纳最新获取的值（通常是最后一个数组元素的属性值），而把之前的值全部当作冗余数据丢弃。
  - 当地图要素是数组结果类型时，采用 “去重合并” 操作：提取每个数组元素中的属性值后，再拼接为一个新的数组，且在拼接过程中，要进行去重操作。
* url 作为地图要素，需要与作为 step 参数的 url，区分开来
  - 作为地图要素的 url，属于文本结果类型，其结果是 data 对象的属性之一，按照 “归一” 操作合并，需要被作为最终结果返回；
  - 作为 step 参数的 url，直接拼接为 urls 数组即可，它是 step 链式运行的中间参数，不需要作为最终结果返回。
* 实际编程时，可以认为原本是 Array 的，就执行“去重合并”；是原始值的，就执行“归一”操作。



## 四、细节设计

### Spider 与引擎的关系

引擎需要借助 Spider 才能完成具体的数据获取，虽然 Spider 也可以被单独调用，但引擎提供了 Spider 的自动运行环境。

**Spider 的设计见 ./Spider/design.md*

### list 与 ListSpider

#### 1. list

* list 的存在是必要的，因为数据需要作为一个整体进行筛选，依据 dataMap 获取的 data 是筛选的依据之一；
* list 不同于 group，group 是指单个数据对象中，其中某些属性的类型是数组结果，它本质上还是一个数据的一个子项。而 list 是多个数据组合而成的列表；group 数据是最终结果的组成，而 list 不是最终的结果，只是一个 step 的中间数据。
* list 的筛选器有两大类，一是最终只保留一个结果，适用于作品信息的搜索；另一是最终保留数个结果，适用于资源链接的搜索。

#### 2. ListSpider

* ListSpider 是 list 的搜索的具体执行者，承担搜索列表数据，并完成筛选工作。
* ListSpider 直接返回获取到的数据列表，不承担数据的合并任务。
* ListSpider 的初始化过程是，借助 DOM 及 `list` 配置，获取一个 element 列表。
* ListSpider 对外提供一个 `search()` 方法，参数是 `dataMap` 配置，返回搜索到的数据结果数组。
  - `search() ` 方法内部会遍历 element 列表，每次遍历都实例化一个 Spider，借助它，并依据 `dataMap`，完成对当前遍历的一个 element 的数据搜索；
  - 筛选借助于筛选器，一次任务只执行一个筛选器。筛选器分两类：
    - 保留多个结果的筛选器：在遍历过程同步完成筛选，将筛选合格的数据添加进“结果数组”中；
    - 只保留一个结果的筛选器：这类筛选器需要滤除大部分数据，只能对整体进行操作，那么会在遍历结束后执行筛选。
  - 返回“结果数组”，完成搜索任务。

### 查询参数设计

引擎配置中，`input` 和 `referer` 都支持查询参数，查询参数的值来源于运行时的上下文，动态生成。

* 查询参数的格式是 `${查询的变量名}`，例如：

  ```js
  {
      input: "${root}/cn/search/${search}"
  }
  ```

  *假如：root 配置为 “https://www.baidu.com”，search 是引擎运行时的输入参数，假设是 "Spider-001"，那么在运行时 input 的具体值就是 "https://www.baidu.com/cn/search/Spider-001"*

* 目前支持的查询参数

  | 参数名 | 意义       | 说明                               |
  | ------ | ---------- | ---------------------------------- |
  | root   | 主页根地址 | 对应于引擎配置中的 `root` 选项     |
  | search | 查找字段   | 来源于执行引擎运行函数时的输入参数 |
  | avid   | 作品番号   | 来源于对 search 字段的解析         |

* input 参数的上下文：在对 input 配置的解析中，需要上下文才能将 input 参数替换成对应的变量值。提供给解析函数的上下文主要来源于运行函数的输入参数，及引擎配置对象。

### 远程网站的访问破解

#### 站点的机器人访问限制：

| 限制                  | 破解方法 |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **跳转主页验证**<br />时段内第一次访问站点时触发，跳转到机器人验证页，几秒后跳转到目标页或网站猜测的上一页；<br />验证成功后的一段时间内可维持正常访问，时间过后会失效重新触发<br />网站猜测的上一页，可能是主页，也可能是查询的中间页。 | 验证须在浏览器完成。<br />发生验证跳转时，由 Tab 承接验证，即转为使用 Tab 打开目标页面，完成验证过程。 |
| **opener限制**<br />查询页必须从同源站点的特定URL打开，否则全部跳转到主页。<br />比如，直接使用 tabs.update() 打开查询页，会跳转到主页 | 这个问题的本质是网站后台会进行"Referer"的判断，对于异源的请求全部重定向到主页。<br />两种破解方法：<br />(1) 通过注入脚本 window.open() 打开。虽然比较简单，但无法控制 Tab 的 active 属性。<br />(2) 动态修改请求头：<br />在请求头中增加"Referer"，指明由谁发起的请求，不是网站主页就可以，对具体 URL 有具体要求。<br />为保险起见，可以一并把"Sec-Fetch-Site"的值设置为"same-origin"<br />*\*答疑：设置 openerTabId 并不能改变请求头。* <br /> *\*Tips： 这两个请求头无法通过  fetch 修改 (见：[MDN](https://developer.mozilla.org/zh-CN/docs/Glossary/Forbidden_header_name))* |
| **访问间隔限制**<br />同一瞬间多次访问站点任一页面，判定为机器人 | 每次访问之间设置随机间隔                                     |

#### 其它要考虑的情况：

| 存在情况                                                     | 解决办法                                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **加载不完成**<br />有时会出现，页面虽然结果已经加载出来了，一直没有 complete（可能在加载某些无关紧要的资源） | 设置超时，不要一直等待。由于加载页面只用于解决验证问题，不获取数据，因此即使超时也无关紧要，只要验证过程完成即可。 |

#### 处理原则：

远程的网络请求，失败不可避免，必须接受失败的可能性。对于目标站点的限制或是网络问题，能处理尽量处理；不能处理，或是处理方案比较复杂的都放弃，直接返回失败，让用户重试。

#### 解决方案：

##### 获取远程 DOM 的核心流程

* 根据请求的地址、配置的 referer，动态修改请求头；
* 尝试用 fetch 请求页面，会有 4 种结果：成功、跳转验证、超时失败、网络问题失败
* 对于成功返回 200 的，获取 DOM， 返回结果
* 对于验证跳转的，使用 Tab 打开验证页，完成验证后重新发起 fetch
* 其它情况均认为失败，返回 null

##### Tab 访问验证页

* 通常的验证流程是，在 Tab 种打开验证页，验证页自己会发起一次请求，后台验证成功会返回之前要访问的页面。
* 因此，在 Tab 种有两次等待，第一次等待验证页的正常打开，第二次等待验证结果页面的返回。

##### 页面加载 Complete 状态判断

* Complete 状态通过向 tabs 绑定事件来判断，并由一个返回 Promise 的方法（例如命名为 whenComplete）管理，支持 await 方式调用该方法。

  **Tip：超时也可以做成一个 Promise，借助 Promise.any() ，可以判断是正常 Complete 返回，还是超时返回。*

* 一个 Tab 经常会加载页面，因此会触发多次事件绑定，这些绑定的事件用一个数组记录起来，当 Tab 被 remove 时，需要全部解绑。

  **Tips：创建一个专门用于绑定事件的方法，承接事件绑定，并完成记录工作。另有一个解绑方法，完成解绑及记录的撤销。*

##### 任务竞争

* 任务竞争是指，正在进行一次搜索任务时，又有另一个新的搜索任务发起，这两个任务形成了竞争。
* 任务竞争可能会导致对目标网站的访问过于频繁而被限制。因此为了防止任务竞争，当一个任务正在进行时，可以拒绝新任务的请求；新任务可以等待旧任务完成返回，或超时返回后再继续。







